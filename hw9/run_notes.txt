
Run on v100a
mpirun -n 2 -H 158.175.75.148,158.175.75.153 --allow-run-as-root hostname


nohup mpirun --allow-run-as-root -n 4 -H 10.45.243.115:2,10.45.243.77:2 -bind-to none -map-by slot --mca btl_tcp_if_include eth0 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH python run.py --config_file=/data/transformer-base.py --use_horovod=True --mode=train_eval &


GPU would not be able to train a full-capacity tensor if the network is the limiting factor. 
Results on github might be somewhat different due to setting differences. Seems like they were restricted by network